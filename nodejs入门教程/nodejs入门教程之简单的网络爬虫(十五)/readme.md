## 学习背景
这一章我们给前面的学习做一个小总结，我们用我们之前学习的知识实现一个小小的网络爬虫，通过这个小工具来加深一下我们之前知识点的学习，同时我们也学习一些cheerio库和got库的简单使用。

## 实现目标
我们实现一个简单的网络爬虫，从`https://www.fabiaoqing.com/biaoqing`表情包网站获取最新的表情包图片，并这些图片保存到本地。其中我们要使用的知识点主要有以下几点：
> 1、http 请求:通过http请求我们从表情包网站获取到我们要的数据，并实现读取网络图片

> 2、fs文件系统:把读取到的网络图片保存到本地

> 3、npm包管理:使用npm来管理我们的第三方库

> 4、第三方库got与cheerio的使用:了解这两个第三方库的的管理与简单的使用



## 创建项目
1、创建项目文件夹“nodejs入门教程之实现简单的网络爬虫”
> 这个没啥可说的

2、初始化npm项目
```cmd
cd `nodejs入门教程之实现简单的网络爬虫`
npm init
```
> npm 项目初始化这个我们之前学习过，这里不做过多赘述了

3、找到满足我们需求功能的包

仔细分析我们要实现的功能，主要有三个主要的模块
- 1从远程服务器请求到数据，这个可以使用我之前建议的的got库
- 2解析请求到的数据并保存，从远程服务器上获取得数据都是html结构得，主要是解析这个html数据，这里我直接推荐大家使用cheerio库，它的使用方式与我们学习的jQuery使用很像
- 3保存我们的图片数据到本地，这个不需要第三方库，可以直接通过系统自带的fs库来完成

>在自己的学习与工作生涯中，需要自己不断的积累这种不同功能的库。当我们遇到问题的时候可以知道哪个库可以解决我们的问题。其次就是用好搜索引擎，找到自己需要的库。

4、安装我们的库

```
npm i got --save

npm i cheerio --save

```
> 通过这两个命令安装got和cheerio库到我们的项目中

5、创建入口程序index.js

> 创建index.js文件我们就开始在这里写我们的主要代码了

## 模块划分

我们分析这个程序主要有三个功能

- 1从远程服务器请求到数据，
- 2解析请求到的数据并保存，
- 3保存我们的图片数据到本地，

那我们就把我们这个程序划分为这三个模块和一个入口模块，分别建
- dataGet.js  负责从远程服务器获取数据
- dataParser.js 负责解析获取的数据
- dataSaver.js 负责把解析出来的数据保存起来
- index.js这个作为程序主模块与入口模块，协调调用上面三个模块来实现我们的功能

## 代码实现

1、数据请求模块dataGet
```js
const got = require('got');

class DataGet {
    constructor() {
    }

    async getData(params) {
        console.log('开始请求远程服务器数据')
        const response = await got(params.url);
        console.log('成功获取到了数据')
        return response.body;
    }
}

module.exports = DataGet
```
该模块主要是根据请求得url地址获取到对于远程服务器得数据，这里得数据是html结构的网页，这个在浏览器的控制台中可以看出来

